{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPzrUhPqpczhf6O539gLyUO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Set GPU runtime first: Runtime > Change Runtime Type > GPU\n",
        "\n",
        "# Check GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_wSYTAjaB9c",
        "outputId": "e8443be3-0c0f-4ae3-c6fe-01360810c147"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul  5 17:00:50 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install specific compatible versions\n",
        "!pip install gymnasium==0.29.1\n",
        "!pip install ale-py==0.9.0\n",
        "!pip install stable-baselines3==2.3.2\n",
        "!pip install autorom[accept-rom-license]==0.6.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gV3Zp_IcUK_",
        "outputId": "021fab63-2bc7-4d89-911a-eed7e6631d8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium==0.29.1\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1) (0.0.4)\n",
            "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gymnasium\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.2.0\n",
            "    Uninstalling gymnasium-1.2.0:\n",
            "      Successfully uninstalled gymnasium-1.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-0.29.1\n",
            "Collecting ale-py==0.9.0\n",
            "  Downloading ale_py-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ale-py==0.9.0) (2.0.2)\n",
            "Downloading ale_py-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ale-py\n",
            "  Attempting uninstall: ale-py\n",
            "    Found existing installation: ale-py 0.11.1\n",
            "    Uninstalling ale-py-0.11.1:\n",
            "      Successfully uninstalled ale-py-0.11.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.9.0 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ale-py-0.9.0\n",
            "Collecting stable-baselines3==2.3.2\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.3.2) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.3.2) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.3.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.3.2) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.3.2) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3==2.3.2) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.3.2) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3==2.3.2) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.3.2) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.3.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.3.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.3.2) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.3.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.3.2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.3.2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13->stable-baselines3==2.3.2)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13->stable-baselines3==2.3.2)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13->stable-baselines3==2.3.2)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13->stable-baselines3==2.3.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13->stable-baselines3==2.3.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13->stable-baselines3==2.3.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.3.2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.3.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.3.2) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13->stable-baselines3==2.3.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.3.2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable-baselines3==2.3.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3==2.3.2) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3==2.3.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.3.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3==2.3.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.3.2) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->stable-baselines3==2.3.2) (3.0.2)\n",
            "Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.3.2\n",
            "Collecting autorom==0.6.1 (from autorom[accept-rom-license]==0.6.1)\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom==0.6.1->autorom[accept-rom-license]==0.6.1) (8.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom==0.6.1->autorom[accept-rom-license]==0.6.1) (2.32.3)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]==0.6.1)\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom==0.6.1->autorom[accept-rom-license]==0.6.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom==0.6.1->autorom[accept-rom-license]==0.6.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom==0.6.1->autorom[accept-rom-license]==0.6.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom==0.6.1->autorom[accept-rom-license]==0.6.1) (2025.6.15)\n",
            "Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446709 sha256=9d2d55d7e6b9ad64fdb53f579ed222c5ac65b741cd7fbd9b5e8337f61141cd4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install ROMs with proper acceptance\n",
        "!AutoROM --accept-license --install-dir /usr/local/lib/python3.11/dist-packages/ale_py/roms"
      ],
      "metadata": {
        "id": "EcJ0Vd9bh3PE",
        "outputId": "ed778661-ea8a-413d-c164-11948147df72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/usr/local/lib/python3.11/dist-packages/ale_py/roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test basic imports first\n",
        "try:\n",
        "    import gymnasium as gym\n",
        "    print(f\"‚úÖ Gymnasium {gym.__version__} imported successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Gymnasium import failed: {e}\")\n",
        "\n",
        "try:\n",
        "    import ale_py\n",
        "    print(f\"‚úÖ ALE-py {ale_py.__version__} imported successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ALE-py import failed: {e}\")\n",
        "\n",
        "try:\n",
        "    import stable_baselines3\n",
        "    print(f\"‚úÖ Stable-Baselines3 {stable_baselines3.__version__} imported successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Stable-Baselines3 import failed: {e}\")"
      ],
      "metadata": {
        "id": "AIFWI0GIiTZ2",
        "outputId": "1be77e2f-706d-4644-dab8-a1940037be28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Gymnasium 0.29.1 imported successfully\n",
            "‚úÖ ALE-py 0.9.0 imported successfully\n",
            "‚úÖ Stable-Baselines3 2.3.2 imported successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import ale_py\n",
        "\n",
        "print(\"üîç Testing Asteroids with compatible versions...\")\n",
        "\n",
        "try:\n",
        "    # Register ALE environments\n",
        "    gym.register_envs(ale_py)\n",
        "    print(\"‚úÖ ALE environments registered\")\n",
        "\n",
        "    # Check available environments\n",
        "    all_envs = list(gym.envs.registry.keys())\n",
        "    asteroid_envs = [env for env in all_envs if 'asteroid' in env.lower()]\n",
        "    print(f\"Asteroid environments found: {asteroid_envs}\")\n",
        "\n",
        "    # Try to create Asteroids environment\n",
        "    if asteroid_envs:\n",
        "        env_name = asteroid_envs[0]\n",
        "        env = gym.make(env_name)\n",
        "        print(f\"‚úÖ Successfully created: {env_name}\")\n",
        "\n",
        "        obs, info = env.reset()\n",
        "        print(f\"‚úÖ Environment reset successful\")\n",
        "        print(f\"  Observation shape: {obs.shape}\")\n",
        "        print(f\"  Action space: {env.action_space}\")\n",
        "\n",
        "        # Test one step\n",
        "        action = env.action_space.sample()\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        print(f\"‚úÖ Environment step successful\")\n",
        "\n",
        "        env.close()\n",
        "        working_env = env_name\n",
        "\n",
        "    else:\n",
        "        # Try direct ALE approach\n",
        "        ale = ale_py.ALEInterface()\n",
        "        available_roms = ale.getAvailableRoms()\n",
        "        print(f\"Available ROMs: {available_roms}\")\n",
        "\n",
        "        if 'asteroids' in available_roms:\n",
        "            ale.loadROM('asteroids')\n",
        "            print(\"‚úÖ Direct ALE Asteroids loading successful\")\n",
        "            working_env = 'direct_ale'\n",
        "        else:\n",
        "            working_env = None\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Environment test failed: {e}\")\n",
        "    working_env = None\n",
        "\n",
        "print(f\"\\nüéØ Working environment: {working_env}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTQOjCw2cZJ1",
        "outputId": "6eb918a5-19b4-4d45-c7e1-6d15b8cceb70"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Testing Asteroids with compatible versions...\n",
            "‚úÖ ALE environments registered\n",
            "Asteroid environments found: ['Asteroids-v0', 'AsteroidsDeterministic-v0', 'AsteroidsNoFrameskip-v0', 'Asteroids-v4', 'AsteroidsDeterministic-v4', 'AsteroidsNoFrameskip-v4', 'Asteroids-ram-v0', 'Asteroids-ramDeterministic-v0', 'Asteroids-ramNoFrameskip-v0', 'Asteroids-ram-v4', 'Asteroids-ramDeterministic-v4', 'Asteroids-ramNoFrameskip-v4', 'ALE/Asteroids-v5', 'ALE/Asteroids-ram-v5']\n",
            "‚úÖ Successfully created: Asteroids-v0\n",
            "‚úÖ Environment reset successful\n",
            "  Observation shape: (210, 160, 3)\n",
            "  Action space: Discrete(14)\n",
            "‚úÖ Environment step successful\n",
            "\n",
            "üéØ Working environment: Asteroids-v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment Asteroids-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DQN Code for Asteroids"
      ],
      "metadata": {
        "id": "aFYiIN3-cDja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from stable_baselines3.common.atari_wrappers import (\n",
        "    ClipRewardEnv,\n",
        "    EpisodicLifeEnv,\n",
        "    FireResetEnv,\n",
        "    MaxAndSkipEnv,\n",
        "    NoopResetEnv,\n",
        ")\n",
        "from stable_baselines3.common.buffers import ReplayBuffer\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Args:\n",
        "    \"\"\"Hyperparameters for Custom Asteroids DQN\"\"\"\n",
        "    exp_name: str = \"custom_asteroids_dqn\"\n",
        "    seed: int = 1\n",
        "    torch_deterministic: bool = True\n",
        "    cuda: bool = True\n",
        "\n",
        "    # Environment - use the working Asteroids environment!\n",
        "    env_id: str = \"AsteroidsNoFrameskip-v4\"  # Use NoFrameskip version for training\n",
        "\n",
        "    # Training parameters\n",
        "    total_timesteps: int = 1000000  # 1M timesteps (~90 minutes)\n",
        "    learning_rate: float = 1e-4\n",
        "    buffer_size: int = 100000\n",
        "    gamma: float = 0.99\n",
        "    target_network_frequency: int = 1000\n",
        "    batch_size: int = 32\n",
        "    start_e: float = 1.0\n",
        "    end_e: float = 0.01\n",
        "    exploration_fraction: float = 0.10\n",
        "    learning_starts: int = 100000\n",
        "    train_frequency: int = 4\n",
        "\n",
        "\n",
        "class CustomQNetwork(nn.Module):\n",
        "    \"\"\"Custom CNN for Asteroids - you can modify this architecture!\"\"\"\n",
        "\n",
        "    def __init__(self, env, hidden_size=512):\n",
        "        super().__init__()\n",
        "        self.env = env\n",
        "\n",
        "        # CNN Feature Extractor - CUSTOMIZE THIS!\n",
        "        self.network = nn.Sequential(\n",
        "            # First conv layer: detect basic shapes\n",
        "            nn.Conv2d(4, 32, 8, stride=4),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Second conv layer: detect movement patterns\n",
        "            nn.Conv2d(32, 64, 4, stride=2),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Third conv layer: complex spatial relationships\n",
        "            nn.Conv2d(64, 64, 3, stride=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        # Calculate conv output size\n",
        "        with torch.no_grad():\n",
        "            sample_input = torch.zeros(1, 4, 84, 84)\n",
        "            conv_output_size = self.network(sample_input).shape[1]\n",
        "\n",
        "        # Value head - CUSTOMIZE THIS!\n",
        "        self.value_head = nn.Sequential(\n",
        "            nn.Linear(conv_output_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size // 2, env.single_action_space.n)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.network(x / 255.0)  # Normalize pixels\n",
        "        return self.value_head(features)\n",
        "\n",
        "\n",
        "def make_env(env_id, seed, idx, capture_video, run_name):\n",
        "    \"\"\"Create Asteroids environment with proper wrappers\"\"\"\n",
        "    def thunk():\n",
        "        if capture_video and idx == 0:\n",
        "            env = gym.make(env_id, render_mode=\"rgb_array\")\n",
        "            env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n",
        "        else:\n",
        "            env = gym.make(env_id)\n",
        "\n",
        "        print(f\"‚úÖ Successfully created environment: {env_id}\")\n",
        "\n",
        "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
        "        env = NoopResetEnv(env, noop_max=30)\n",
        "        env = MaxAndSkipEnv(env, skip=4)\n",
        "        env = EpisodicLifeEnv(env)\n",
        "\n",
        "        if \"FIRE\" in env.unwrapped.get_action_meanings():\n",
        "            env = FireResetEnv(env)\n",
        "\n",
        "        env = ClipRewardEnv(env)\n",
        "        env = gym.wrappers.ResizeObservation(env, (84, 84))\n",
        "        env = gym.wrappers.GrayScaleObservation(env)\n",
        "        env = gym.wrappers.FrameStack(env, 4)\n",
        "\n",
        "        env.action_space.seed(seed)\n",
        "        return env\n",
        "    return thunk\n",
        "\n",
        "\n",
        "def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
        "    \"\"\"Linear decay for exploration\"\"\"\n",
        "    slope = (end_e - start_e) / duration\n",
        "    return max(slope * t + start_e, end_e)\n",
        "\n",
        "\n",
        "def train_asteroids_dqn():\n",
        "    \"\"\"Main training function\"\"\"\n",
        "    args = Args()\n",
        "\n",
        "    # Setup\n",
        "    run_name = f\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
        "    writer = SummaryWriter(f\"runs/{run_name}\")\n",
        "\n",
        "    # Seeding\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.backends.cudnn.deterministic = args.torch_deterministic\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
        "\n",
        "    # Environment\n",
        "    envs = gym.vector.SyncVectorEnv([\n",
        "        make_env(args.env_id, args.seed, 0, True, run_name)\n",
        "    ])\n",
        "\n",
        "    # Networks\n",
        "    q_network = CustomQNetwork(envs, hidden_size=512).to(device)\n",
        "    optimizer = optim.Adam(q_network.parameters(), lr=args.learning_rate)\n",
        "    target_network = CustomQNetwork(envs, hidden_size=512).to(device)\n",
        "    target_network.load_state_dict(q_network.state_dict())\n",
        "\n",
        "    # Experience Replay\n",
        "    rb = ReplayBuffer(\n",
        "        args.buffer_size,\n",
        "        envs.single_observation_space,\n",
        "        envs.single_action_space,\n",
        "        device,\n",
        "        handle_timeout_termination=False,\n",
        "    )\n",
        "\n",
        "    # Training Loop\n",
        "    obs, _ = envs.reset(seed=args.seed)\n",
        "    episode_rewards = []\n",
        "    episode_lengths = []\n",
        "\n",
        "    for global_step in range(args.total_timesteps):\n",
        "        # Exploration rate\n",
        "        epsilon = linear_schedule(\n",
        "            args.start_e, args.end_e,\n",
        "            args.exploration_fraction * args.total_timesteps,\n",
        "            global_step\n",
        "        )\n",
        "\n",
        "        # Action selection\n",
        "        if random.random() < epsilon:\n",
        "            actions = np.array([envs.single_action_space.sample()])\n",
        "        else:\n",
        "            q_values = q_network(torch.Tensor(obs).to(device))\n",
        "            actions = torch.argmax(q_values, dim=1).cpu().numpy()\n",
        "\n",
        "        # Environment step\n",
        "        next_obs, rewards, terminations, truncations, infos = envs.step(actions)\n",
        "\n",
        "        # Track metrics\n",
        "        if \"final_info\" in infos:\n",
        "            for info in infos[\"final_info\"]:\n",
        "                if info and \"episode\" in info:\n",
        "                    episode_rewards.append(info[\"episode\"][\"r\"])\n",
        "                    episode_lengths.append(info[\"episode\"][\"l\"])\n",
        "                    writer.add_scalar(\"charts/episodic_return\", info[\"episode\"][\"r\"], global_step)\n",
        "                    writer.add_scalar(\"charts/episodic_length\", info[\"episode\"][\"l\"], global_step)\n",
        "                    print(f\"Step {global_step}, Episode reward: {info['episode']['r']}\")\n",
        "\n",
        "        # Store experience\n",
        "        real_next_obs = next_obs.copy()\n",
        "        for idx, d in enumerate(terminations):\n",
        "            if d:\n",
        "                real_next_obs[idx] = infos[\"final_observation\"][idx]\n",
        "\n",
        "        rb.add(obs, real_next_obs, actions, rewards, terminations, infos)\n",
        "        obs = next_obs\n",
        "\n",
        "        # Training\n",
        "        if global_step > args.learning_starts:\n",
        "            if global_step % args.train_frequency == 0:\n",
        "                data = rb.sample(args.batch_size)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    target_max, _ = target_network(data.next_observations).max(dim=1)\n",
        "                    td_target = data.rewards.flatten() + args.gamma * target_max * (1 - data.dones.flatten())\n",
        "\n",
        "                old_val = q_network(data.observations).gather(1, data.actions).squeeze()\n",
        "                loss = F.mse_loss(td_target, old_val)\n",
        "\n",
        "                if global_step % 1000 == 0:\n",
        "                    writer.add_scalar(\"losses/td_loss\", loss, global_step)\n",
        "                    writer.add_scalar(\"losses/q_values\", old_val.mean().item(), global_step)\n",
        "                    writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
        "\n",
        "                # Optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        # Update target network\n",
        "        if global_step % args.target_network_frequency == 0:\n",
        "            target_network.load_state_dict(q_network.state_dict())\n",
        "\n",
        "    # Save model\n",
        "    model_path = f\"models/{run_name}.pt\"\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    torch.save(q_network.state_dict(), model_path)\n",
        "\n",
        "    envs.close()\n",
        "    writer.close()\n",
        "\n",
        "    return q_network, episode_rewards, model_path\n",
        "\n",
        "\n",
        "def evaluate_model(model_path, num_episodes=10):\n",
        "    \"\"\"Evaluate trained model on Asteroids\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Create environment\n",
        "    env = gym.vector.SyncVectorEnv([make_env(\"AsteroidsNoFrameskip-v4\", 42, 0, False, \"eval\")])\n",
        "    q_network = CustomQNetwork(env).to(device)\n",
        "    q_network.load_state_dict(torch.load(model_path))\n",
        "    q_network.eval()\n",
        "\n",
        "    print(f\"‚úÖ Evaluating on: AsteroidsNoFrameskip-v4\")\n",
        "\n",
        "    # Evaluate\n",
        "    obs, _ = env.reset()\n",
        "    episode_rewards = []\n",
        "    episode_lengths = []\n",
        "    current_reward = 0\n",
        "    current_length = 0\n",
        "\n",
        "    for step in range(50000):  # Max steps for evaluation\n",
        "        with torch.no_grad():\n",
        "            q_values = q_network(torch.Tensor(obs).to(device))\n",
        "            actions = torch.argmax(q_values, dim=1).cpu().numpy()\n",
        "\n",
        "        obs, rewards, terminations, truncations, infos = env.step(actions)\n",
        "        current_reward += rewards[0]\n",
        "        current_length += 1\n",
        "\n",
        "        if terminations[0] or truncations[0]:\n",
        "            episode_rewards.append(current_reward)\n",
        "            episode_lengths.append(current_length)\n",
        "            print(f\"Episode {len(episode_rewards)}: {current_reward} points, {current_length} steps\")\n",
        "\n",
        "            current_reward = 0\n",
        "            current_length = 0\n",
        "            obs, _ = env.reset()\n",
        "\n",
        "            if len(episode_rewards) >= num_episodes:\n",
        "                break\n",
        "\n",
        "    env.close()\n",
        "\n",
        "    # Results\n",
        "    avg_reward = np.mean(episode_rewards)\n",
        "    avg_length = np.mean(episode_lengths)\n",
        "\n",
        "    print(f\"\\nüìä Evaluation Results:\")\n",
        "    print(f\"Average Score: {avg_reward:.1f}\")\n",
        "    print(f\"Average Length: {avg_length:.0f}\")\n",
        "    print(f\"Best Score: {max(episode_rewards)}\")\n",
        "    print(f\"Episodes: {len(episode_rewards)}\")\n",
        "\n",
        "    return episode_rewards, episode_lengths\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = time.time()\n",
        "    print(\"üöÄ Starting Custom Asteroids DQN Training...\")\n",
        "\n",
        "    # Train the model\n",
        "    model, rewards, model_path = train_asteroids_dqn()\n",
        "\n",
        "    print(f\"‚úÖ Training completed! Model saved to: {model_path}\")\n",
        "    print(f\"Training time: {(time.time() - start_time)/60:.1f} minutes\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(\"\\nüéØ Evaluating trained model...\")\n",
        "    eval_rewards, eval_lengths = evaluate_model(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0tX9nSIcC74",
        "outputId": "4d9f1875-1500-4359-cb4b-f78f1e158139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting Custom Asteroids DQN Training...\n",
            "‚úÖ Successfully created environment: AsteroidsNoFrameskip-v4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-8-59313764.py:200: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
            "  real_next_obs[idx] = infos[\"final_observation\"][idx]\n",
            "/usr/local/lib/python3.11/dist-packages/moviepy/config_defaults.py:1: DeprecationWarning: invalid escape sequence '\\P'\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video /content/videos/AsteroidsNoFrameskip-v4__custom_asteroids_dqn__1__1751735191/rl-video-episode-0.mp4.\n",
            "Moviepy - Writing video /content/videos/AsteroidsNoFrameskip-v4__custom_asteroids_dqn__1__1751735191/rl-video-episode-0.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-8-59313764.py:200: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
            "  real_next_obs[idx] = infos[\"final_observation\"][idx]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/videos/AsteroidsNoFrameskip-v4__custom_asteroids_dqn__1__1751735191/rl-video-episode-0.mp4\n",
            "Step 538, Episode reward: [480.]\n",
            "Moviepy - Building video /content/videos/AsteroidsNoFrameskip-v4__custom_asteroids_dqn__1__1751735191/rl-video-episode-1.mp4.\n",
            "Moviepy - Writing video /content/videos/AsteroidsNoFrameskip-v4__custom_asteroids_dqn__1__1751735191/rl-video-episode-1.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/videos/AsteroidsNoFrameskip-v4__custom_asteroids_dqn__1__1751735191/rl-video-episode-1.mp4\n",
            "Step 1287, Episode reward: [530.]\n",
            "Step 2179, Episode reward: [680.]\n",
            "Step 3627, Episode reward: [1180.]\n",
            "Step 4253, Episode reward: [830.]\n",
            "Step 4806, Episode reward: [610.]\n",
            "Step 6743, Episode reward: [1300.]\n",
            "Step 7237, Episode reward: [230.]\n",
            "Moviepy - Building video /content/videos/AsteroidsNoFrameskip-v4__custom_asteroids_dqn__1__1751735191/rl-video-episode-8.mp4.\n",
            "Moviepy - Writing video /content/videos/AsteroidsNoFrameskip-v4__custom_asteroids_dqn__1__1751735191/rl-video-episode-8.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/videos/AsteroidsNoFrameskip-v4__custom_asteroids_dqn__1__1751735191/rl-video-episode-8.mp4\n",
            "Step 7733, Episode reward: [180.]\n",
            "Step 9281, Episode reward: [1490.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3YgwQQaa4Yj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}